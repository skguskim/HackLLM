# --- CTF09 ---
import streamlit as st
from utils.llm_utils import ctf09_LLM_ask
from utils.ui import render_main_header, render_flag_sub

render_main_header()

st.markdown("# ğŸ”’ [CTF09] ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ìš”ì²­")

st.write(
    """
    í•œ LLM(GPT-3.5)ì€ ê°œì¸ì •ë³´ë³´í˜¸ ê´€ë ¨ ì§€ì‹ì´ ë¶€ì¡±í•˜ì—¬ ë¶€ì •í™•í•œ ì •ë³´ë¥¼ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
    ë‹¤ë¥¸ LLM(GPT-4.0 Mini)ëŠ” ì´ë¥¼ ê²€í† í•˜ì—¬ ì˜ëª»ëœ ì •ë³´ë¥¼ íŒë³„í•©ë‹ˆë‹¤.  
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë”°ë¼ ë‘ LLMì˜ ì‘ë‹µì„ ë¹„êµí•˜ê³ , ì‘ë‹µ ì–´ë”˜ê°€ì—ì„œ í”Œë˜ê·¸ë¥¼ ì°¾ì•„ ì œì¶œí•˜ì„¸ìš”.
    """
)

st.markdown("---")
st.markdown("## ğŸ§  í”„ë¡¬í”„íŠ¸ ì…ë ¥")

# í”„ë¡¬í”„íŠ¸ ì œì¶œ ì„¹ì…˜
user_input = st.text_input("ğŸ“¨ LLMì— ì§ˆë¬¸í•˜ê¸°")

if user_input:
    response_text = ctf09_LLM_ask(user_input)
    llm1_text, llm2_text = response_text.split("ğŸ“Œ LLM2 (ì „ë¬¸ê°€)ì˜ í‰ê°€:\n")

    st.markdown("### ğŸ§  LLM1 (ì§€ì‹ ë¶€ì¡±)ì˜ ì‘ë‹µ")
    st.code(llm1_text.strip().replace("ğŸ“Œ LLM1 (ì§€ì‹ ë¶€ì¡±)ì˜ ì‘ë‹µ:\n", ""), language="markdown")

    st.markdown("### ğŸ§  LLM2 (ì „ë¬¸ê°€)ì˜ í‰ê°€")
    st.code(llm2_text.strip(), language="markdown")

st.markdown("---")

# í”Œë˜ê·¸ ì œì¶œ ì„¹ì…˜
flag = "flag{misinformation_llm_wrong_law}"
render_flag_sub(flag, "ctf09")
