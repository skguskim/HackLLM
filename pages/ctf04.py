import streamlit as st
from utils.llm_utils import ctf04_LLM_ask
from utils.ui import render_main_header, render_flag_sub
import csv
import io
import chardet
from sentence_transformers import SentenceTransformer
import chromadb
import uuid

@st.cache_resource
def setup_vector_db():
    model = SentenceTransformer("all-MiniLM-L6-v2")
    client = chromadb.PersistentClient(path="./ctf04_chroma")

    try:
        client.delete_collection("ctf04_docs")
    except:
        pass

    collection = client.create_collection("ctf04_docs")

    with open("data/ctf04_dataset.txt", "r", encoding="utf-8") as f:
        base_text = f.read()
        base_embedding = model.encode(base_text).tolist()
        collection.add(
            documents=[base_text],
            ids=["base_doc"],
            embeddings=[base_embedding],
            metadatas=[{"source": "ctf04_dataset.txt"}]
        )

    return model, collection

def generate_prompt_from_csv(csv_text):
    f = io.StringIO(csv_text)
    reader = csv.reader(f)
    lines = []
    for row in reader:
        lines.extend(row)
    cleaned = [line.strip() for line in lines if line.strip()]
    return "\n".join(cleaned)

def try_decode(raw_data) -> tuple[str | None, str]:
    """raw_dataë¥¼ ë‹¤ì–‘í•œ ì¸ì½”ë”©ìœ¼ë¡œ ë””ì½”ë”© ì‹œë„"""
    encodings_to_try = ["utf-8", "cp949", "euc-kr", "iso-8859-1"]

    for enc in encodings_to_try:
        try:
            text = raw_data.decode(enc)
            return text, f"{enc}"
        except UnicodeDecodeError:
            continue

    # chardet ìë™ ì¸ì½”ë”© ê°ì§€
    result = chardet.detect(raw_data)
    encoding = result.get("encoding")
    confidence = result.get("confidence", 0)

    if encoding:
        try:
            text = raw_data.decode(encoding)
            return text, f"{encoding} (ìë™ê°ì§€, ì‹ ë¢°ë„ {confidence*100:.1f}%)"
        except:
            pass

render_main_header()

st.header("ğŸ”’ [CTF04] ì¸í„´ì˜ ì‹¤ìˆ˜")
st.write("CSVë¥¼ í†µí•´, íŠ¹ì • ì§ˆë¬¸ì„ í•˜ì—¬ flagë¥¼ íšë“í•´ë³´ì„¸ìš”.")

st.markdown("---")
st.markdown("## ğŸ—‚ï¸ CSV ì‚½ì…")

uploaded_file = st.file_uploader("íŒŒì¼ ì—…ë¡œë“œ (.txt, .csv)", type=["csv", "txt"])

if uploaded_file:
    model, collection = setup_vector_db()

    # íŒŒì¼ì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸
    raw_data = uploaded_file.read()
    text, encoding_info = try_decode(raw_data)

    if not text.strip():
        st.error("íŒŒì¼ ë‚´ìš©ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
    else:
        st.success(f"{encoding_info}ë¡œ ì½ì—ˆìŠµë‹ˆë‹¤.")

        embedding = model.encode(text)
        embedding_list = embedding.tolist()
        embeddings = [embedding_list]

        unique_id = f"user_doc_{uuid.uuid4()}"

        collection.add(
            documents=[text],
            ids=[unique_id],
            embeddings=embeddings,
            metadatas=[{"source": uploaded_file.name}]
        )
else:
    st.session_state["ctf04_uploaded"] = False
    st.info("ğŸ“‚ ë¬¸ì„œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.(.txt, .csv)")

st.markdown("---")
user_input = st.text_input("ğŸ§  í”„ë¡¬í”„íŠ¸ ì…ë ¥")

if user_input:
    if "ctf04_model" not in st.session_state or "ctf04_collection" not in st.session_state:
        model, collection = setup_vector_db()
        st.session_state["ctf04_model"] = model
        st.session_state["ctf04_collection"] = collection
    else:
        model = st.session_state["ctf04_model"]
        collection = st.session_state["ctf04_collection"]

    with st.spinner("LLM ì‘ë‹µ ìƒì„± ì¤‘..."):
        response_text = ctf04_LLM_ask(user_input, model, collection)
        st.write("ğŸ§  LLM ì‘ë‹µ:")
        st.code(response_text)

# FLAG ì œì¶œ
st.markdown("---")
flag = "flag{poison}"
render_flag_sub(flag, "ctf04")